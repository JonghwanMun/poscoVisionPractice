{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import math\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Load MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer Fuctions\n",
    "  - Linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linearLayer(inp, inp_dim, out_dim, with_relu=False, \\\n",
    "                with_dropout=False, use_contribute=False, prefix='hidden'):\n",
    "    \"\"\" Linear layer\n",
    "    Args:\n",
    "        inp: input data, [batch_size, inp_dim]\n",
    "        inp_dim: input dimension\n",
    "        out_dim: output dimension\n",
    "    Returns:\n",
    "        out: Output tensor with the computed logits, [batch_size, out_dim]\n",
    "             return (inp * weight + bias)\n",
    "    \"\"\"\n",
    "    print '%s: %d-dim ->%d-dim (relu: %s, dropout: %s, contribute:%s)' \\\n",
    "            % (prefix, inp_dim, out_dim, with_relu, with_dropout, use_contribute)\n",
    "    \n",
    "    with tf.name_scope(prefix):\n",
    "        if not use_contribute :\n",
    "            weight = tf.Variable(TODO_FillHere, name='weights')\n",
    "            bias = tf.Variable(tf.zeros([out_dim]), name='biases')\n",
    "            out = tf.matmul(inp, weight) + bias\n",
    "            \n",
    "            if with_relu : TODO = True\n",
    "            if with_dropout : TODO = True\n",
    "                \n",
    "        else :\n",
    "            if with_dropout : TODO = True\n",
    "            else : TODO = True\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Model Construction Functions\n",
    " - Network (3-layer NN)\n",
    "     - $h_1 = W_1^Tx+b_1$  (hidden dimension=128)\n",
    "     - $h_2= W_2^Th_1+b_2$ (hidden dimension=32)\n",
    "     - $h_3= W_3^Th_2+b_3$ (hidden dimension=number of label=10)\n",
    "     - $\\hat{y} = \\text{softmax}(h_3)$\n",
    " - Loss function\n",
    "     - Cross-entropy loss\n",
    "     - $-\\sum_k{y_{i,k}\\log{\\hat{y}_{i,k}}}$\n",
    " - Optimization algorithm\n",
    "     - gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def buildInputHolders():\n",
    "    \"\"\" define placeholders for model inputs\n",
    "    Returns:\n",
    "        img_holder: images placeholder\n",
    "        label_hodler: labels placeholder\n",
    "    \"\"\"\n",
    "    img_holder = tf.placeholder(tf.float32, [None, 28*28])\n",
    "    label_holder = tf.placeholder(tf.float32, [None, 10])\n",
    "    \n",
    "    return img_holder, label_holder\n",
    "    \n",
    "def buildInference(images, img_dim, label_num, hidden1_units, hidden2_units):\n",
    "    \"\"\"Build the MNIST model up to where it may be used for inference.\n",
    "    Args:\n",
    "        images: Images placeholder, from inputs().\n",
    "        hidden1_units: Size of the first hidden layer.\n",
    "        hidden2_units: Size of the second hidden layer.\n",
    "    Returns:\n",
    "        pred: Output tensor with the computed logits.\n",
    "    \"\"\"\n",
    "    # Hidden 1\n",
    "    hidden1 = linearLayer(images, img_dim, hidden1_units, prefix='hidden1')\n",
    "    # Hidden 2\n",
    "    hidden2 = linearLayer(hidden1, hidden1_units,hidden2_units, prefix='hidden2')\n",
    "    # Linear\n",
    "    pred = linearLayer(hidden2, hidden2_units, \\\n",
    "                       label_num, with_relu=False, prefix='linear')\n",
    "    return tf.nn.softmax(pred)\n",
    "\n",
    "def buildLoss(preds, labels):\n",
    "    \"\"\"Calculates the loss from the predictions and the labels.\n",
    "    Args:\n",
    "        preds  : prediction tensor, [batch_size, NUM_CLASSES]\n",
    "        labels : labels tensor, [batch_size]\n",
    "    Returns:\n",
    "        loss : loss tensor of type float\n",
    "    \"\"\"\n",
    "    cross_entropy_loss = -tf.reduce_sum(labels * tf.log(preds), reduction_indices=[1])\n",
    "    return tf.reduce_mean(cross_entropy_loss)\n",
    "\n",
    "def buildAccuracy(pred, labels):\n",
    "    \"\"\"Calculates the accuracy from the predictions and the labels.\n",
    "    Args:\n",
    "        preds  : prediction tensor, [batch_size, NUM_CLASSES]\n",
    "        labels : labels tensor, [batch_size]\n",
    "    Returns:\n",
    "        accuracy : accuracy tensor of type float\n",
    "    \"\"\"\n",
    "    correct_prediction = tf.equal(tf.argmax(pred,1), tf.argmax(labels,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "def buildModel(params):\n",
    "    \"\"\" Build Model\n",
    "    Args:\n",
    "        params : dictionary data for parameters {\n",
    "            'batch_size' : batch size\n",
    "            'lr' : learning rate\n",
    "            }\n",
    "    Returns:\n",
    "        imgs : input images of model\n",
    "        labels : input labels of model\n",
    "        train_step : one step operation for training\n",
    "        loss : Loss tensor\n",
    "        acc : accuracy\n",
    "    \"\"\"\n",
    "    imgs, labels = buildInputHolders()\n",
    "    preds = buildInference(imgs, 28*28, 10, 128, 32)\n",
    "    loss = buildLoss(preds, labels)\n",
    "    acc = buildAccuracy(preds, labels)\n",
    "    \n",
    "    global_step = tf.Variable(.0, trainable=False)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(params['lr'])\n",
    "    train_step = optimizer.minimize(loss, global_step=global_step)\n",
    "    \n",
    "    return imgs, labels, train_step, loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# define parameters\n",
    "params = {}\n",
    "params['batch_size'] = 100\n",
    "params['lr'] = 0.5\n",
    "params['total_batch'] = int(mnist.train.num_examples/params['batch_size'])\n",
    "\n",
    "# build model\n",
    "imgs, labels, train_step, loss, acc = buildModel(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 Avg. cost = 2.303\n",
      "Epoch: 0002 Avg. cost = 2.302\n",
      "Epoch: 0003 Avg. cost = 2.302\n",
      "Epoch: 0004 Avg. cost = 2.302\n",
      "Epoch: 0005 Avg. cost = 2.302\n",
      "Epoch: 0006 Avg. cost = 2.302\n",
      "Epoch: 0007 Avg. cost = 2.302\n",
      "Epoch: 0008 Avg. cost = 2.302\n",
      "Epoch: 0009 Avg. cost = 2.302\n",
      "Epoch: 0010 Avg. cost = 2.302\n",
      "Test Accuracy:  0.1135\n"
     ]
    }
   ],
   "source": [
    "batch_size = params['batch_size']\n",
    "total_batch = params['total_batch']\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(10):\n",
    "        total_cost = 0\n",
    "\n",
    "        for i in range(total_batch):\n",
    "            # batch 데이터를 가져옴\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            # 모델 업데이트 수행\n",
    "            _, cost_val = sess.run([train_step, loss], \\\n",
    "                                   feed_dict={imgs: batch_xs, labels: batch_ys})\n",
    "            total_cost += cost_val\n",
    "\n",
    "        print \"Epoch:\", \"%02d\" % (epoch + 1), \\\n",
    "            \"Avg. cost =\", '{:.3f}'.format(total_cost / total_batch)\n",
    "\n",
    "    # 테스트 데이터에 대한 정확도\n",
    "    print \"Test Accuracy: \", sess.run(acc, \\\n",
    "                    feed_dict={imgs: mnist.test.images, labels: mnist.test.labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note! 딥 러닝 모델의 성능이 오르는 데 크게 기여한 방법들\n",
    "  - Activation function\n",
    "    - ReLu\n",
    "      - $f(x) = max(0,x)$\n",
    "      - Non linearlity 함수\n",
    "      - tf.nn.relu(features)를 이용하여 간단하게 구현 가능\n",
    "          - features: relu를 적용 할 tensor\n",
    "      - https://www.tensorflow.org/api_docs/python/tf/nn/relu\n",
    "      - <img src=\"../resource/relu.png\" width=\"250\" height=\"250\">\n",
    "  - Regularization\n",
    "    - Dropout\n",
    "      - 데이터에서 임의의 값들을 0으로 대체 (모델의 overfitting을 완화)\n",
    "      - tf.nn.dropout(x, keep_prob)를 이용하여 간단하게 구현 가능\n",
    "          - x: dropout를 적용 할 tensor\n",
    "          - keep_prob: 데이터를 유지 할 확률 (1: 모든 데이터 유지, 0: 모든 데이터를 0으로)\n",
    "      - https://www.tensorflow.org/api_docs/python/tf/nn/dropout\n",
    "      - <img src=\"../resource/dropout.png\" width=\"400\" height=\"300\">\n",
    "    - Others\n",
    "      - L1 regularization\n",
    "      - L2 regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ReLu 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=(1,10))\n",
    "relu_x = tf.nn.relu(x)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    inp = np.random.randn(1,10)\n",
    "    print \"input x:\\n\", inp\n",
    "    print \"relu_x:\\n\", sess.run(relu_x, {x:inp})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=(1,10))\n",
    "dropout_x = tf.nn.dropout(x, 0.5)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    inp = np.random.randn(1,10)\n",
    "    print \"input x:\\n\", inp\n",
    "    print \"dropout_x:\\n\", sess.run(dropout_x, {x:inp})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
