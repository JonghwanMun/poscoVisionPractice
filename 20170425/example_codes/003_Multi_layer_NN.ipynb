{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Load MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Model Construction Functions\n",
    " - Network (3-hidden-layer softmax regression)\n",
    "     - $h_1 = W_1^Tx+b_1$  (hidden dimension=128)\n",
    "     - $h_2= W_2^Th_1+b_2$ (hidden dimension=32)\n",
    "     - $h_3= W_3^Th_2+b_3$ (hidden dimension=number of label=10)\n",
    "     - $\\hat{y} = \\text{softmax}(h_3)$\n",
    " - Loss function\n",
    "     - Cross-entropy loss\n",
    "     - $-\\sum_k{y_{i,k}\\log{\\hat{y}_{i,k}}}$\n",
    " - Optimization algorithm\n",
    "     - gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Functions of layer definition\n",
    "def linearLayer(inp, inp_dim, out_dim, with_relu=False, prefix='hidden'):\n",
    "    \"\"\" Linear layer\n",
    "    Args:\n",
    "        inp: input data, [batch_size, inp_dim]\n",
    "        inp_dim: input dimension\n",
    "        out_dim: output dimension\n",
    "    Returns:\n",
    "        out: Output tensor with the computed logits, [batch_size, out_dim]\n",
    "             return (inp * weight + bias)\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.name_scope(prefix):\n",
    "        weight = tf.Variable(tf.zeros([inp_dim, out_dim]), name='weights')\n",
    "        bias = tf.Variable(tf.zeros([out_dim]),name='biases')\n",
    "        \n",
    "        out = tf.matmul(inp, weight) + bias\n",
    "        if with_relu :\n",
    "            TODO = True\n",
    "    return out\n",
    "\n",
    "# Functions of model construction\n",
    "def buildInputHolders():\n",
    "    \"\"\" define placeholders for model inputs\n",
    "    Returns:\n",
    "        img_holder: images placeholder\n",
    "        label_hodler: labels placeholder\n",
    "    \"\"\"\n",
    "    img_holder = tf.placeholder(tf.float32, [None, 28*28])\n",
    "    label_holder = tf.placeholder(tf.float32, [None, 10])\n",
    "    \n",
    "    return img_holder, label_holder\n",
    "    \n",
    "def buildInference(images, img_dim, label_num, hidden1_units, hidden2_units):\n",
    "    \"\"\"Build the MNIST model up to where it may be used for inference.\n",
    "    Args:\n",
    "        images: Images placeholder, from inputs().\n",
    "        hidden1_units: Size of the first hidden layer.\n",
    "        hidden2_units: Size of the second hidden layer.\n",
    "    Returns:\n",
    "        pred: Output tensor with the computed logits.\n",
    "    \"\"\"\n",
    "    # Hidden 1\n",
    "    hidden1 = linearLayer(images, img_dim, hidden1_units, \\\n",
    "                          with_relu=True, prefix='hidden1')\n",
    "    # Hidden 2\n",
    "    hidden2 = linearLayer(hidden1, hidden1_units, \\\n",
    "                          hidden2_units, with_relu=True, prefix='hidden2')\n",
    "    # Linear\n",
    "    pred = linearLayer(hidden2, hidden2_units, \\\n",
    "                       label_num, with_relu=False, prefix='linear')\n",
    "    return tf.nn.softmax(pred)\n",
    "\n",
    "def buildLoss(preds, labels):\n",
    "    \"\"\"Calculates the loss from the predictions and the labels.\n",
    "    Args:\n",
    "        preds  : prediction tensor, [batch_size, NUM_CLASSES]\n",
    "        labels : labels tensor, [batch_size]\n",
    "    Returns:\n",
    "        loss : loss tensor of type float\n",
    "    \"\"\"\n",
    "    cross_entropy_loss = -tf.reduce_sum(labels * tf.log(preds), reduction_indices=[1])\n",
    "    return tf.reduce_mean(cross_entropy_loss)\n",
    "\n",
    "def buildAccuracy(pred, labels):\n",
    "    \"\"\"Calculates the accuracy from the predictions and the labels.\n",
    "    Args:\n",
    "        preds  : prediction tensor, [batch_size, NUM_CLASSES]\n",
    "        labels : labels tensor, [batch_size]\n",
    "    Returns:\n",
    "        accuracy : accuracy tensor of type float\n",
    "    \"\"\"\n",
    "    correct_prediction = tf.equal(tf.argmax(pred,1), tf.argmax(labels,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "def buildModel(params):\n",
    "    \"\"\" Build Model\n",
    "    Args:\n",
    "        params : dictionary data for parameters {\n",
    "            'batch_size' : batch size\n",
    "            'lr' : learning rate\n",
    "            }\n",
    "    Returns:\n",
    "        imgs : input images of model\n",
    "        labels : input labels of model\n",
    "        train_step : one step operation for training\n",
    "        loss : Loss tensor\n",
    "        acc : accuracy\n",
    "    \"\"\"\n",
    "    imgs, labels = buildInputHolders()\n",
    "    preds = buildInference(imgs, 28*28, 10, 128, 32)\n",
    "    loss = buildLoss(preds, labels)\n",
    "    acc = buildAccuracy(preds, labels)\n",
    "    \n",
    "    global_step = tf.Variable(.0, trainable=False)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(params['lr'])\n",
    "    train_step = optimizer.minimize(loss, global_step=global_step)\n",
    "    \n",
    "    return imgs, labels, train_step, loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# define parameters\n",
    "params = {}\n",
    "params['batch_size'] = 100\n",
    "params['lr'] = 0.5\n",
    "params['total_batch'] = int(mnist.train.num_examples/params['batch_size'])\n",
    "\n",
    "# build model\n",
    "imgs, labels, train_step, loss, acc = buildModel(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 Avg. cost = 2.303\n",
      "Epoch: 0002 Avg. cost = 2.302\n",
      "Epoch: 0003 Avg. cost = 2.302\n",
      "Epoch: 0004 Avg. cost = 2.302\n",
      "Epoch: 0005 Avg. cost = 2.302\n",
      "Epoch: 0006 Avg. cost = 2.302\n",
      "Epoch: 0007 Avg. cost = 2.302\n",
      "Epoch: 0008 Avg. cost = 2.302\n",
      "Epoch: 0009 Avg. cost = 2.302\n",
      "Epoch: 0010 Avg. cost = 2.302\n",
      "Test Accuracy:  0.1135\n"
     ]
    }
   ],
   "source": [
    "batch_size = params['batch_size']\n",
    "total_batch = params['total_batch']\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(10):\n",
    "        total_cost = 0\n",
    "\n",
    "        for i in range(total_batch):\n",
    "            # batch 데이터를 가져옴\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            # 모델 업데이트 수행\n",
    "            _, cost_val = sess.run([train_step, loss], \\\n",
    "                                   feed_dict={imgs: batch_xs, labels: batch_ys})\n",
    "            total_cost += cost_val\n",
    "\n",
    "        print( \"Epoch:\", \"%04d\" % (epoch + 1), \\\n",
    "            \"Avg. cost =\", '{:.3f}'.format(total_cost / total_batch))\n",
    "\n",
    "    # 테스트 데이터에 대한 정확도\n",
    "    print(\"Test Accuracy: \", sess.run(acc, \\\n",
    "                    feed_dict={imgs: mnist.test.images, labels: mnist.test.labels}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
