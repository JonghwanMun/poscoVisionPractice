{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1. Load MNIST data\n",
    "  - 55,000/10,000/5,000 points for train/val/test\n",
    "  - images \n",
    "      - mnist.\\*.images (\\* $\\in$ train, validation, test)\n",
    "      - size: (1, 28*28)\n",
    "  - labels\n",
    "      - mnist.\\*.labels (\\* $\\in$ train, validation, test)\n",
    "      - one-hot vector (1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### MNIST 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image size:  (55000, 784)\n",
      "label size:  (55000, 10)\n"
     ]
    }
   ],
   "source": [
    "# print size of images and labels\n",
    "print('image size: ', mnist.train.images.shape)\n",
    "print('label size: ', mnist.train.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nd9Ikvq2dAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbe5cd97b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      "label: 5\n"
     ]
    }
   ],
   "source": [
    "idx = random.randint(0, mnist.train.images.shape[0])\n",
    "img = mnist.train.images[idx, :]\n",
    "label = mnist.train.labels[idx, :]\n",
    "img = img.reshape(28,28)\n",
    "\n",
    "plt.imshow(img, cmap=plt.cm.Greys)\n",
    "plt.show()\n",
    "print('label: {}'.format(label))\n",
    "print('label: {}'.format(np.argmax(label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2. Single-layer NN\n",
    " - Network\n",
    "     - $\\hat{y}= \\text{softmax}(W^Tx+b)$\n",
    " - Loss function\n",
    "     - Cross-entropy loss\n",
    "     - $-\\sum_k{y_{i,k}\\log{\\hat{y}_{i,k}}}$\n",
    " - Optimization algorithm\n",
    "     - 실제 레이블 y를 예측하도록 하는 W와 b를 찾음\n",
    "     - gradient descent\n",
    "         - $\\theta = \\theta -lr * d\\theta~~$ where $\\theta \\in W,b$\n",
    " - 약 92%의 성능이 나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f8405462323b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../resource/single_layer_NN.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"off\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Image' is not defined"
     ]
    }
   ],
   "source": [
    "img = Image.open(\"../resource/single_layer_NN.png\")\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\"); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\" 인풋 데이터 및 레이블 정의\n",
    "  인풋 데이터를 받기 위해 tensorflow placeholder를 만들고, \n",
    "  그 크기는 [batch_size, 데이터 크기]로 정의합니다. 또한, \n",
    "  인풋 데이터의 레이블을 받기 위해 [batch_size, 레이블 수]\n",
    "  크기의 placeholder를 정의합니다.\n",
    "  note: 여기에서 batch_size는 None으로 둠으로 임의의\n",
    "  batch_size의 데이터를 인풋으로 받게 됩니다.\n",
    "\"\"\"\n",
    "inps = tf.placeholder(tf.float32, [None, 784])\n",
    "labels = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\" softmax regressor 모델 정의\n",
    "  y = softmax(Wx + b)의 연산을 수행하는 모델을 정의합니다.\n",
    "\"\"\"\n",
    "W = tf.Variable(tf.zeros([784, 10])) # weight\n",
    "b = tf.Variable(tf.zeros([10]))      # bias\n",
    "\n",
    "pred = tf.nn.softmax( tf.matmul(inps, W) + b ) # softmax(W*x + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\" loss 및 optimizer 정의\n",
    "  cross-entropy loss를 정의하고, gradient descent 방법으로 \n",
    "  loss가 작아지도록 모델을 업데이트하는 optimizer를 정의합니다.  \n",
    "\"\"\"\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(labels * tf.log(pred), reduction_indices=[1]))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.05).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\" 정확도 정의\n",
    "  정확도 = 맞춘 데이터 수 / 전체 데이터 수\n",
    "\"\"\"\n",
    "# 예측한 레이블과 실제 레이블이 같은 데이터의 수를 계산\n",
    "correct_prediction = tf.equal(tf.argmax(pred,1), tf.argmax(labels,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 Avg. cost = 0.676\n",
      "Epoch: 0002 Avg. cost = 0.417\n",
      "Epoch: 0003 Avg. cost = 0.375\n",
      "Epoch: 0004 Avg. cost = 0.353\n",
      "Epoch: 0005 Avg. cost = 0.340\n",
      "Epoch: 0006 Avg. cost = 0.330\n",
      "Epoch: 0007 Avg. cost = 0.323\n",
      "Epoch: 0008 Avg. cost = 0.316\n",
      "Epoch: 0009 Avg. cost = 0.312\n",
      "Epoch: 0010 Avg. cost = 0.307\n",
      "Test Accuracy:  0.9169\n"
     ]
    }
   ],
   "source": [
    "\"\"\" 모델 학습\n",
    "  정의한 모델을 실제로 tensoerflow의 session에서 \n",
    "  forward/backward를 수행하고 모델의 파라미터를 업데이트합니다.\n",
    "\"\"\"\n",
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples/batch_size)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    # epoch: training 데이터 전체를 다 보는 경우를 의미\n",
    "    # 아래의 경우 10 epoch 동안 모델을 학습함\n",
    "    for epoch in range(10):\n",
    "        total_cost = 0\n",
    "\n",
    "        # iteration (i): 하나의 batch를 보는 경우를 의미\n",
    "        for i in range(total_batch):\n",
    "            # batch 데이터를 가져옴\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            # 모델 업데이트 수행\n",
    "            # sess.run(수행하고자 하는 연산, 연산을 수행하기 위해 요구되는 placeholder를 제공)\n",
    "            _, cost_val = sess.run([train_step, cross_entropy], \\\n",
    "                                   feed_dict={inps: batch_xs, labels: batch_ys})\n",
    "            total_cost += cost_val\n",
    "\n",
    "        print( \"Epoch:\", \"%04d\" % (epoch + 1), \\\n",
    "            \"Avg. cost =\", '{:.3f}'.format(total_cost / total_batch))\n",
    "\n",
    "    # 테스트 데이터에 대한 정확도\n",
    "    print(\"Test Accuracy: \", sess.run(accuracy, \\\n",
    "                    feed_dict={inps: mnist.test.images, labels: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note!!\n",
    "  - learning rate 바꿔서 학습해보기 [0.99, 0.9, 0.1, 0.05, 0.01, 0.005, 0.001]\n",
    "  - 10 epoch 학습 시 정확도 아래값과 유사한지 확인\n",
    "    - [0.9215, 0.9251, 0.921, 0.9195, 0.903, 0.8914, 0.8537]\n",
    "  - learning rate가 낮으면 같은 epoch 대비 모델 업데이트를 적게함으로 학습 속도가 느려짐을 확인할 수 있음 (epoch 수를 늘려 최종 성능도 확인해봅시다)\n",
    "  - 모델을 빠르게 학습하고, 높은 성능을 위해서는 learning rate를 잘 선택하는 것이 중요"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
