{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy.misc import imread, imresize\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "class_names = ['airplane',  'automobile',  'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pre_process_image(image, training):\n",
    "    if training:\n",
    "        # 이미지를 랜덤으로 좌우 반전.\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "        \n",
    "        # 이미지의 명도, 채도 등을 랜덤으로 변경\n",
    "        image = tf.image.random_hue(image, max_delta=0.05)\n",
    "        image = tf.image.random_contrast(image, lower=0.3, upper=1.0)\n",
    "        image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "        image = tf.image.random_saturation(image, lower=0.0, upper=2.0)\n",
    "        \n",
    "        # 혹시 변경하는 중에 값이 초과하지 않았는지 확인\n",
    "        image = tf.minimum(image, 255.0)\n",
    "        image = tf.maximum(image, 0.0)\n",
    "        \n",
    "    image = tf.image.resize_images(image, [224, 224])\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pre_process(images, training):\n",
    "    images = tf.map_fn(lambda image: pre_process_image(image, training), images)\n",
    "\n",
    "    return images\n",
    "def to_array(image):\n",
    "    with tf.Session():\n",
    "        arr = image.eval()\n",
    "        return arr\n",
    "def to_arrays(images):\n",
    "    arrs = tf.map_fn(lambda image: to_array(image), images)\n",
    "    return arrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 변수 설정\n",
    "x = tf.placeholder(tf.float32, shape=[None, 32, 32, 3], name='x')\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, 10], name='y_true')\n",
    "y_true_cls = tf.argmax(y_true, dimension=1)\n",
    "\n",
    "distorted_images = pre_process(images=x, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class vgg16:\n",
    "    def __init__(self, imgs, sess=None):\n",
    "        self.imgs = imgs\n",
    "        self.convlayers()\n",
    "        self.fc_layers()\n",
    "        self.probs = tf.nn.softmax(self.fc4l)\n",
    "\n",
    "    def convlayers(self):\n",
    "        self.parameters = []\n",
    "\n",
    "        # zero-mean input\n",
    "        with tf.name_scope('preprocess') as scope:\n",
    "            mean = tf.constant([123.68, 116.779, 103.939], dtype=tf.float32, shape=[1, 1, 1, 3], name='img_mean')\n",
    "            images = self.imgs-mean\n",
    "\n",
    "        # conv1_1\n",
    "        with tf.name_scope('conv1_1') as scope:\n",
    "            # TODO \n",
    "            kernel = \n",
    "            conv = \n",
    "            biases = \n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv1_1 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # conv1_2\n",
    "        with tf.name_scope('conv1_2') as scope:\n",
    "            # TODO\n",
    "            kernel = \n",
    "            conv = \n",
    "            biases = \n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv1_2 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # pool1\n",
    "        self.pool1 = \n",
    "\n",
    "        # conv2_1\n",
    "        with tf.name_scope('conv2_1') as scope:\n",
    "            kernel = \n",
    "            conv = \n",
    "            biases = \n",
    "            out = \n",
    "            self.conv2_1 = \n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # conv2_2\n",
    "        with tf.name_scope('conv2_2') as scope:\n",
    "            kernel = \n",
    "            conv = \n",
    "            biases = \n",
    "            out = \n",
    "            self.conv2_2 = \n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # pool2\n",
    "        self.pool2 = \n",
    "\n",
    "        # conv3_1\n",
    "        with tf.name_scope('conv3_1') as scope:\n",
    "            kernel = \n",
    "            conv = \n",
    "            biases = \n",
    "            out = \n",
    "            self.conv3_1 = \n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # conv3_2\n",
    "        with tf.name_scope('conv3_2') as scope:\n",
    "            kernel = \n",
    "            conv = \n",
    "            biases = \n",
    "            out = \n",
    "            self.conv3_2 =\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # conv3_3\n",
    "        with tf.name_scope('conv3_3') as scope:\n",
    "            kernel = \n",
    "            conv =\n",
    "            biases =\n",
    "            out = \n",
    "            self.conv3_3 = \n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # pool3\n",
    "        self.pool3 = \n",
    "\n",
    "        # conv4_1\n",
    "        with tf.name_scope('conv4_1') as scope:\n",
    "            kernel = \n",
    "            conv = \n",
    "            biases = \n",
    "            out = \n",
    "            self.conv4_1 = \n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # conv4_2\n",
    "        with tf.name_scope('conv4_2') as scope:\n",
    "            kernel = \n",
    "            conv = \n",
    "            biases = \n",
    "            out = t\n",
    "            self.conv4_2 = \n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # conv4_3\n",
    "        with tf.name_scope('conv4_3') as scope:\n",
    "            kernel = \n",
    "            conv = \n",
    "            biases = \n",
    "            out = \n",
    "            self.conv4_3 = \n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # pool4\n",
    "        self.pool4 = \n",
    "\n",
    "        # conv5_1\n",
    "        with tf.name_scope('conv5_1') as scope:\n",
    "            kernel =\n",
    "            conv = \n",
    "            biases = \n",
    "            out = \n",
    "            self.conv5_1 = \n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # conv5_2\n",
    "        with tf.name_scope('conv5_2') as scope:\n",
    "            kernel = \n",
    "            conv = \n",
    "            biases = \n",
    "            out = \n",
    "            self.conv5_2 = \n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # conv5_3\n",
    "        with tf.name_scope('conv5_3') as scope:\n",
    "            kernel = \n",
    "            conv = \n",
    "            biases = \n",
    "            out = \n",
    "            self.conv5_3 = \n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # pool5\n",
    "        self.pool5 = \n",
    "\n",
    "    def fc_layers(self):\n",
    "        # fc1\n",
    "        with tf.name_scope('fc1') as scope:\n",
    "            shape = int(np.prod(self.pool5.get_shape()[1:]))\n",
    "            fc1w = \n",
    "            fc1b = \n",
    "            pool5_flat = tf.reshape(self.pool5, [-1, shape])\n",
    "            fc1l = \n",
    "            self.fc1 = \n",
    "            self.parameters += [fc1w, fc1b]\n",
    "\n",
    "        # fc2\n",
    "        with tf.name_scope('fc2') as scope:\n",
    "            fc2w = \n",
    "            fc2b = \n",
    "            fc2l = \n",
    "            self.fc2 = \n",
    "            self.parameters += [fc2w, fc2b]\n",
    "\n",
    "        # fc3\n",
    "        with tf.name_scope('fc3') as scope:\n",
    "            fc3w = \n",
    "            fc3b = \n",
    "            self.fc3l = \n",
    "            self.parameters += [fc3w, fc3b]\n",
    "        # fc4\n",
    "        with tf.name_scope('fc4') as scope:\n",
    "            fc4w = \n",
    "            fc4b = \n",
    "            self.fc4l =\n",
    "            self.parameters += [fc4w, fc4b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Label을 one-hot vector로 바꾸어주는 함수 \n",
    "def makeLabel(y):\n",
    "    result = np.zeros((y.shape[0], 10))\n",
    "    cnt = 0\n",
    "    for i in y:\n",
    "        result[cnt, i] = 1.\n",
    "        cnt += 1\n",
    "    return result\n",
    "\n",
    "# Batch를 가져오는 파트를 직접 구현해야 함. \n",
    "def get_batch(batch_size, iteration, train=True):\n",
    "    # Batch_size만큼 image와 label one-hot vector를 만들어 리턴한다.\n",
    "    if not train:\n",
    "        if batch_size*(iteration+1)-1 < len(x_test):\n",
    "            batch_x = x_test[(batch_size*iteration):(batch_size*(iteration+1))]\n",
    "            batch_y = makeLabel(y_test[(batch_size*iteration):(batch_size*(iteration+1))])\n",
    "        else:\n",
    "            batch_x = x_test[(batch_size*iteration):len(x_test)]\n",
    "            batch_y = makeLabel(y_test[(batch_size*iteration):len(x_test)])\n",
    "    if batch_size*(iteration+1)-1 < len(x_train):\n",
    "        batch_x = x_train[(batch_size*iteration):(batch_size*(iteration+1))]\n",
    "        batch_y = makeLabel(y_train[(batch_size*iteration):(batch_size*(iteration+1))])\n",
    "    else:\n",
    "        batch_x = x_train[(batch_size*iteration):len(x_train)]\n",
    "        batch_y = makeLabel(y_train[(batch_size*iteration):len(x_train)])\n",
    "    return (batch_x, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "vgg16 = vgg16(distorted_images, sess)\n",
    "\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_true * tf.log(vgg16.probs), reduction_indices=[1]))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.005).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" 정확도 정의\n",
    "  정확도 = 맞춘 데이터 수 / 전체 데이터 수\n",
    "\"\"\"\n",
    "# 예측한 레이블과 실제 레이블이 같은 데이터의 수를 계산\n",
    "correct_prediction = tf.equal(tf.argmax(vgg16.probs,1), y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 96\n",
    "total_batch = int(len(x_train)/batch_size)\n",
    "init = tf.variables_initializer([fc8_W, fc8_B])\n",
    "\n",
    "sess.run(init)\n",
    "\n",
    "# epoch: training 데이터 전체를 다 보는 경우를 의미\n",
    "# 아래의 경우 1 epoch 동안 모델을 학습함\n",
    "for epoch in range(1):\n",
    "    total_cost = 0\n",
    "\n",
    "    # iteration (i): 하나의 batch를 보는 경우를 의미\n",
    "    for i in range(total_batch):\n",
    "        # batch 데이터를 가져옴\n",
    "        batch_xs, batch_ys = get_batch(batch_size, i)\n",
    "        # 모델 업데이트 수행\n",
    "        # sess.run(수행하고자 하는 연산, 연산을 수행하기 위해 요구되는 placeholder를 제공)\n",
    "        _, cost_val = sess.run([train_step, cross_entropy], \\\n",
    "                                feed_dict={x: batch_xs, y_true: batch_ys})\n",
    "        \n",
    "        total_cost += cost_val\n",
    "        if i % 50 == 0:\n",
    "            print \"Iter: \", \"%d/%d\" % (i, total_batch), \\\n",
    "                  \"Avg. cost=\", '{:.3f}'.format(total_cost / (i+1))\n",
    "        \n",
    "    print \"Epoch:\", \"%02d\" % (epoch + 1), \\\n",
    "        \"Avg. cost =\", '{:.3f}'.format(total_cost / total_batch)\n",
    "\n",
    "# 테스트 데이터에 대한 정확도\n",
    "total_batch_test = int(len(x_test)/batch_size)\n",
    "total_acc = 0\n",
    "for i in range(total_batch_test):\n",
    "    batch_xs, batch_ys = get_batch(batch_size, i)\n",
    "    \n",
    "    acc = sess.run(accuracy, feed_dict={x: batch_xs, y_true: batch_ys})\n",
    "    total_acc += acc\n",
    "    \n",
    "print \"Test Accuracy: \", total_acc / total_batch_test"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
