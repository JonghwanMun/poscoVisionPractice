{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### API reference\n",
    "  - https://www.tensorflow.org/api_docs/python/tf/contrib/layers  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Load MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1. 아래의 구조를 가지는 CNN 작성\n",
    "  - Network (2 convolutional followed by 2 fully connected (linear) layer)\n",
    "    - conv1: output_dim (32), filter_size (3,3), stride (2) without dropout\n",
    "    - max_pool1: filter size (2,2), stride (2)\n",
    "    - conv2: output_dim (64), filter_size (3,3) with dropout (keep_prob=0.8)\n",
    "    - max_pool2: filter size (2,2), stride (2)\n",
    "    - flat_feat: linear 연산을 위해 convolutional layer를 통과한 값을 (1, *)의 벡터로 변환, 결과적으로 (batch_size, *)의 매트릭스를 반환\n",
    "    - fc1: linear layer (output_dim: 256) with dropout (keep_prob=0.8)\n",
    "    - fc2: linear layer (output_dim: # of labels) without relu, dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildInference(images, num_labels):\n",
    "    \"\"\" Build CNN network\n",
    "    Args:\n",
    "        images: 인풋 이미지\n",
    "        num_lables: 레이블 수\n",
    "    Returns:\n",
    "        return CNN network \n",
    "    \"\"\"\n",
    "    # TODO: 아래 layer를 정의하세요.\n",
    "    conv1     = tf.contrib.layers.conv2d(images, 32, [3, 3])\n",
    "    max_pool1 = tf.contrib.layers.max_pool2d(conv1, [2, 2])\n",
    "    conv2     = tf.contrib.layers.conv2d(max_pool1, 64, [3, 3],\n",
    "                    normalizer_fn=tf.nn.dropout,\n",
    "                    normalizer_params={'keep_prob': 0.8})\n",
    "    max_pool2 = tf.contrib.layers.max_pool2d(conv2, [2, 2])\n",
    "\n",
    "    flat_feat = tf.contrib.layers.flatten(max_pool2)\n",
    "\n",
    "    # TODO: 아래 layer를 정의하세요.\n",
    "    fc1 = tf.contrib.layers.fully_connected(flat_feat, 256)\n",
    "    fc2 = tf.contrib.layers.fully_connected(fc1, num_labels, activation_fn=None)\n",
    "    \n",
    "    return tf.nn.softmax(fc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2. 각자의 CNN 모델 구성하기\n",
    "  - filter size, layer 수 등을 바꿔서 구성해보세요.\n",
    "  - 마지막 layer들은 위와 같이 (flat_feat -> fc1 -> fc2)가 되도록 해주세요.\n",
    "  - 단 fc1의 output_dim은 바꾸셔도 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 각자의 네트워크이므로 솔루션 제공 X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildYourInference(images, num_labels):\n",
    "    \"\"\" Build CNN network\n",
    "    Args:\n",
    "        images: 인풋 이미지\n",
    "        num_lables: 레이블 수\n",
    "    Returns:\n",
    "        return CNN network \n",
    "    \"\"\"\n",
    "    # TODO: 아래 각자의 layer를 정의하세요.\n",
    "\n",
    "\n",
    "    flat_feat = tf.contrib.layers.flatten(       )\n",
    "    fc1 = \n",
    "    fc2 = \n",
    "    \n",
    "    return tf.nn.softmax(fc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Model Construction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Functions of model construction\n",
    "def buildInputHolders():\n",
    "    \"\"\" define placeholders for model inputs\n",
    "    Returns:\n",
    "        img_holder: images placeholder\n",
    "        label_hodler: labels placeholder\n",
    "    \"\"\"\n",
    "    img_holder = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "    label_holder = tf.placeholder(tf.float32, [None, 10])\n",
    "    \n",
    "    return img_holder, label_holder\n",
    "\n",
    "def buildLoss(preds, labels):\n",
    "    \"\"\"Calculates the loss from the predictions and the labels.\n",
    "    Args:\n",
    "        preds  : prediction tensor, [batch_size, NUM_CLASSES]\n",
    "        labels : labels tensor, [batch_size]\n",
    "    Returns:\n",
    "        loss : loss tensor of type float\n",
    "    \"\"\"\n",
    "    cross_entropy_loss = -tf.reduce_sum(labels * tf.log(preds), reduction_indices=[1])\n",
    "    return tf.reduce_mean(cross_entropy_loss)\n",
    "\n",
    "def buildAccuracy(pred, labels):\n",
    "    \"\"\"Calculates the accuracy from the predictions and the labels.\n",
    "    Args:\n",
    "        preds  : prediction tensor, [batch_size, NUM_CLASSES]\n",
    "        labels : labels tensor, [batch_size]\n",
    "    Returns:\n",
    "        accuracy : accuracy tensor of type float\n",
    "    \"\"\"\n",
    "    correct_prediction = tf.equal(tf.argmax(pred,1), tf.argmax(labels,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "def buildModel(params):\n",
    "    \"\"\" Build Model\n",
    "    Args:\n",
    "        params : dictionary data for parameters {\n",
    "            'batch_size' : batch size\n",
    "            'lr' : learning rate\n",
    "            }\n",
    "    Returns:\n",
    "        imgs : input images of model\n",
    "        labels : input labels of model\n",
    "        train_step : one step operation for training\n",
    "        loss : Loss tensor\n",
    "        acc : accuracy\n",
    "    \"\"\"\n",
    "    imgs, labels = buildInputHolders()\n",
    "    preds = buildInference(imgs, 10)\n",
    "    #preds = buildYourInference(imgs, 10)\n",
    "    loss = buildLoss(preds, labels)\n",
    "    acc = buildAccuracy(preds, labels)\n",
    "    \n",
    "    global_step = tf.Variable(.0, trainable=False)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(params['lr'])\n",
    "    train_step = optimizer.minimize(loss, global_step=global_step)\n",
    "    \n",
    "    return imgs, labels, train_step, loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# define parameters\n",
    "params = {}\n",
    "params['batch_size'] = 100\n",
    "params['lr'] = 0.1\n",
    "params['total_batch'] = int(mnist.train.num_examples/params['batch_size'])\n",
    "\n",
    "# build model\n",
    "imgs, labels, train_step, loss, acc = buildModel(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 Avg. cost = 0.305\n",
      "Epoch: 02 Avg. cost = 0.087\n",
      "Epoch: 03 Avg. cost = 0.061\n",
      "Epoch: 04 Avg. cost = 0.047\n",
      "Epoch: 05 Avg. cost = 0.039\n",
      "Epoch: 06 Avg. cost = 0.032\n",
      "Epoch: 07 Avg. cost = 0.028\n",
      "Epoch: 08 Avg. cost = 0.023\n",
      "Epoch: 09 Avg. cost = 0.020\n",
      "Epoch: 10 Avg. cost = 0.018\n",
      "Test Accuracy:  0.9892\n"
     ]
    }
   ],
   "source": [
    "batch_size = params['batch_size']\n",
    "total_batch = params['total_batch']\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(10):\n",
    "        total_cost = 0\n",
    "\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            # 이미지 데이터를 CNN 모델을 위한 자료형태인 [height width channel] 의 형태로 재구성합니다.\n",
    "            batch_xs = batch_xs.reshape(-1, 28, 28, 1)\n",
    "            \n",
    "            _, cost_val = sess.run([train_step, loss], \\\n",
    "                                   feed_dict={imgs: batch_xs, labels: batch_ys})\n",
    "            total_cost += cost_val\n",
    "\n",
    "        print \"Epoch:\", \"%02d\" % (epoch + 1), \\\n",
    "            \"Avg. cost =\", '{:.3f}'.format(total_cost / total_batch)\n",
    "\n",
    "    # 테스트 데이터에 대한 정확도\n",
    "    print \"Test Accuracy: \", sess.run(acc, \\\n",
    "                    feed_dict={imgs: mnist.test.images.reshape(-1, 28, 28, 1), \\\n",
    "                               labels: mnist.test.labels})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
