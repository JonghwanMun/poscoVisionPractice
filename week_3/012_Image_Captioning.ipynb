{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from vgg16 import vgg16\n",
    "from dataLoader import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Data download\n",
    "  - 다운로드 제대로 된 후에는 다시 실행할 필요 없습니다 :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('resource/vgg16_weights.npz'):\n",
    "    # download images\n",
    "    os.system('wget cvlab.postech.ac.kr/~jonghwan/224x224_mscoco_images.tar.gz')\n",
    "    os.system('tar xvzf 224x224_mscoco_images.tar.gz')\n",
    "    os.system('rm 224x224_mscoco_images.tar.gz')\n",
    "    os.system('mv 224x224_mscoco_images resource/224x224_mscoco_images')\n",
    "\n",
    "    # download vgg16 network\n",
    "    os.system('wget cvlab.postech.ac.kr/~jonghwan/vgg16_weights.npz')\n",
    "    os.system('mv vgg16_weights.npz resource/vgg16_weights.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Captioning Network Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Caption_Generator():\n",
    "    def init_weight(self, dim_in, dim_out, name=None, stddev=1.0):\n",
    "        return tf.Variable(tf.truncated_normal([dim_in, dim_out], stddev=stddev/math.sqrt(float(dim_in))), name=name)\n",
    "\n",
    "    def init_bias(self, dim_out, name=None):\n",
    "        return tf.Variable(tf.zeros([dim_out]), name=name)\n",
    "\n",
    "    def __init__(self, params, bias_init_vector=None):\n",
    "        #dim_image, dim_embed, dim_hidden, batch_size, n_lstm_steps, n_words, bias_init_vector=None):\n",
    "        \n",
    "        self.wtoi = params['wtoi']\n",
    "        self.vgg16_weight_file = params['vgg16_weight_file']\n",
    "        \n",
    "        # captioning model parameter dimensions\n",
    "        self.dim_image_feat = np.int(params['dim_image'])\n",
    "        self.dim_word_embedding = np.int(params['dim_embed'])\n",
    "        self.dim_hidden_lstm = np.int(params['dim_hidden'])\n",
    "        self.batch_size = np.int(params['batch_size'])\n",
    "        self.n_lstm_steps = np.int(params['n_lstm_steps'])\n",
    "        self.n_words = np.int(params['n_words'])\n",
    "        \n",
    "        self.initializer = tf.random_uniform_initializer(minval=-0.8, maxval=0.8)\n",
    "\n",
    "    def build_model(self, sess):\n",
    "        \"\"\" Build captioning model for training\"\"\"\n",
    "\n",
    "        image = tf.placeholder(tf.float32, [self.batch_size, 224, 224, 3])\n",
    "        input_labels = tf.placeholder(tf.int32, [self.batch_size, self.n_lstm_steps])\n",
    "        target_labels = tf.placeholder(tf.int32, [self.batch_size, self.n_lstm_steps])\n",
    "        mask = tf.placeholder(tf.float32, [self.batch_size, self.n_lstm_steps])\n",
    "\n",
    "        # extract image feature\n",
    "        vgg = vgg16(image, self.vgg16_weight_file, sess, trainable=False)\n",
    "        image_feat = vgg.fc7\n",
    "        \n",
    "        # embed image feature to match the dimension of lstm input\n",
    "        with tf.variable_scope(\"image_embedding\") as img_embed_scope:\n",
    "            image_embeddings = tf.contrib.layers.fully_connected(\n",
    "                                    inputs=image_feat,\n",
    "                                    num_outputs=self.dim_hidden_lstm,\n",
    "                                    activation_fn=None,\n",
    "                                    weights_initializer=self.initializer,\n",
    "                                    biases_initializer=None,\n",
    "                                    scope=img_embed_scope)\n",
    "            \n",
    "        # embed input caption labels to obtain word embeddings\n",
    "        with tf.variable_scope(\"word_embedding\"), tf.device('/cpu:0'):\n",
    "            word_embedding_matrix = tf.get_variable(\n",
    "                                        name='word_embedding_matrix',\n",
    "                                        shape=[self.n_words, self.dim_word_embedding],\n",
    "                                        initializer=self.initializer\n",
    "                                        )\n",
    "            word_embeddings = tf.nn.embedding_lookup(word_embedding_matrix, input_labels)\n",
    "                                                            \n",
    "        \n",
    "        # for LSTM cell unit\n",
    "        with tf.variable_scope(\"lstm\", initializer=self.initializer) as lstm_scope:\n",
    "            lstm_cell = tf.contrib.rnn.BasicLSTMCell(num_units=self.dim_hidden_lstm, state_is_tuple=True)\n",
    "            zero_state = lstm_cell.zero_state(self.batch_size, dtype=tf.float32)\n",
    "            _, initial_state = lstm_cell(image_embeddings, zero_state)\n",
    "            \n",
    "            # allow the LSTM variables to be resued\n",
    "            lstm_scope.reuse_variables()\n",
    "            \n",
    "            # run the batch of word embeddings throught the LSTM\n",
    "            caption_length = tf.reduce_sum(mask, 1)\n",
    "            lstm_outputs, _ = tf.nn.dynamic_rnn(cell=lstm_cell,\n",
    "                                               inputs=word_embeddings,\n",
    "                                               sequence_length=caption_length,\n",
    "                                               initial_state=initial_state,\n",
    "                                               dtype=tf.float32,\n",
    "                                               scope=lstm_scope)\n",
    "        \n",
    "        # stack batches vertically\n",
    "        lstm_outputs = tf.reshape(lstm_outputs, [-1, lstm_cell.output_size])\n",
    "        \n",
    "        # compute probabilities for words\n",
    "        with tf.variable_scope(\"logits\") as logits_scope:\n",
    "            logits = tf.contrib.layers.fully_connected(\n",
    "                        inputs=lstm_outputs,\n",
    "                        num_outputs=self.n_words,\n",
    "                        activation_fn=None,\n",
    "                        weights_initializer=self.initializer,\n",
    "                        scope=logits_scope)\n",
    "        \n",
    "        targets = tf.reshape(target_labels, [-1])\n",
    "        weights = tf.to_float(tf.reshape(mask, [-1]))\n",
    "        \n",
    "        # compute losses\n",
    "        losses = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=targets,\n",
    "                                                              logits=logits)\n",
    "        batch_loss = tf.div(tf.reduce_sum(tf.multiply(losses, weights)),\n",
    "                            tf.reduce_sum(weights), name=\"batch_loss\")\n",
    "        tf.losses.add_loss(batch_loss)\n",
    "        total_loss = tf.losses.get_total_loss()\n",
    "        \n",
    "        probs = tf.nn.softmax(logits, name='softmax')\n",
    "\n",
    "        return image, input_labels, target_labels, mask, total_loss, probs\n",
    "\n",
    "    def build_generator(self, sess):\n",
    "        \"\"\" Build captioning model for test\"\"\"\n",
    "        \n",
    "        # extract image feature\n",
    "        image = tf.placeholder(tf.float32, [self.batch_size, 224, 224, 3], name='image_raw')\n",
    "        vgg = vgg16(image, self.vgg16_weight_file, sess, trainable=False)\n",
    "        image_feat = vgg.fc7\n",
    "        \n",
    "        # embed image feature to match the dimension of lstm input\n",
    "        with tf.variable_scope(\"image_embedding\") as img_embed_scope:\n",
    "            encoded_images = tf.contrib.layers.fully_connected(\n",
    "                                    inputs=image_feat,\n",
    "                                    num_outputs=self.dim_hidden_lstm,\n",
    "                                    activation_fn=None,\n",
    "                                    weights_initializer=self.initializer,\n",
    "                                    biases_initializer=None,\n",
    "                                    scope=img_embed_scope)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Below part is for caption generation (LSTM)\n",
    "        image_embeddings = tf.placeholder(dtype=tf.float32,\n",
    "                                          shape=[self.batch_size, self.dim_hidden_lstm],\n",
    "                                          name='image_feed')\n",
    "        input_feed = tf.placeholder(dtype=tf.int64, shape=[None], name='input_feed')\n",
    "        input_labels = tf.expand_dims(input_feed, 1)\n",
    "\n",
    "        # embed input caption labels to obtain word embeddings\n",
    "        with tf.variable_scope(\"word_embedding\"), tf.device('/cpu:0'):\n",
    "            word_embedding_matrix = tf.get_variable(\n",
    "                                        name='word_embedding_matrix',\n",
    "                                        shape=[self.n_words, self.dim_word_embedding],\n",
    "                                        initializer=self.initializer\n",
    "                                        )\n",
    "            word_embeddings = tf.nn.embedding_lookup(word_embedding_matrix, input_labels)                                                            \n",
    "        \n",
    "        # for LSTM cell unit    \n",
    "        with tf.variable_scope(\"lstm\", initializer=self.initializer) as lstm_scope:\n",
    "            lstm_cell = tf.contrib.rnn.BasicLSTMCell(num_units=self.dim_hidden_lstm, state_is_tuple=True)\n",
    "            zero_state = lstm_cell.zero_state(self.batch_size, dtype=tf.float32)\n",
    "            _, initial_state = lstm_cell(image_embeddings, zero_state)\n",
    "            \n",
    "            # allow the LSTM variables to be resued\n",
    "            lstm_scope.reuse_variables()\n",
    "            \n",
    "            # In inference mode, use concatenated states for convenient feeding and fetching.\n",
    "            tf.concat(axis=1, values=initial_state, name=\"initial_state\")\n",
    "        \n",
    "        \n",
    "            # Placeholder for feeding a batch of concatenated states.\n",
    "            state_feed = tf.placeholder(dtype=tf.float32,\n",
    "                                        shape=[None, sum(lstm_cell.state_size)],\n",
    "                                        name=\"state_feed\")\n",
    "            state_tuple = tf.split(value=state_feed, num_or_size_splits=2, axis=1)\n",
    "\n",
    "            # Run a single LSTM step.\n",
    "            lstm_outputs, state_tuple = lstm_cell(\n",
    "                inputs=tf.squeeze(word_embeddings, axis=[1]), state=state_tuple)\n",
    "\n",
    "            #lstm_outputs, state_tuple = tf.nn.dynamic_rnn(cell=lstm_cell,\n",
    "            #                                   inputs=word_embeddings,\n",
    "            #                                   initial_state=state_tuple,\n",
    "            #                                   dtype=tf.float32,\n",
    "            #                                   scope=lstm_scope)\n",
    "            \n",
    "            # Concatentate the resulting state.\n",
    "            tf.concat(axis=1, values=state_tuple, name=\"state\")\n",
    "            \n",
    "        \n",
    "        # stack batches vertically\n",
    "        lstm_outputs = tf.reshape(lstm_outputs, [-1, lstm_cell.output_size])\n",
    "        \n",
    "        # compute probabilities for words\n",
    "        with tf.variable_scope(\"logits\") as logits_scope:\n",
    "            logits = tf.contrib.layers.fully_connected(\n",
    "                        inputs=lstm_outputs,\n",
    "                        num_outputs=self.n_words,\n",
    "                        activation_fn=None,\n",
    "                        weights_initializer=self.initializer,\n",
    "                        scope=logits_scope)\n",
    "        probs = tf.nn.softmax(logits, name='softmax')\n",
    "\n",
    "        return image, encoded_images, image_embeddings, state_feed, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "################### Parameters #####################\n",
    "train_params = {\n",
    "    'json_path':'resource/train.json',\n",
    "    'h5py_path':'resource/train.h5',\n",
    "    'img_dir': 'resource/224x224_mscoco_images/'\n",
    "}\n",
    "test_params = {\n",
    "    'json_path':'resource/test.json',\n",
    "    'h5py_path':'resource/test.h5',\n",
    "    'img_dir': 'resource/224x224_mscoco_images/'\n",
    "}\n",
    "# create data loader for training and test data\n",
    "loaders = {}\n",
    "loaders['train'] = dataLoader(train_params)\n",
    "loaders['test'] = dataLoader(test_params)\n",
    "\n",
    "model_params = {\n",
    "    'wtoi': loaders['train'].getWtoi(),\n",
    "    'vgg16_weight_file': 'resource/vgg16_weights.npz',\n",
    "    'dim_image': 4096, # dimension of vgg16 network output\n",
    "    'dim_embed': 256,\n",
    "    'dim_hidden': 256,\n",
    "    'batch_size': 50,\n",
    "    'n_lstm_steps': loaders['train'].getMaxCaptionLength(),\n",
    "    'n_words': loaders['train'].getVocabSize(),\n",
    "}\n",
    "\n",
    "\n",
    "def train():\n",
    "    n_epochs = 100\n",
    "    learning_rate = 0.001\n",
    "    model_path = './models'\n",
    "    itow = loaders['test'].getItow()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "    \n",
    "        caption_generator = Caption_Generator(model_params)#, bias_init_vector=bias_init_vector)\n",
    "        image, input_labels, target_labels, mask, loss, prob = caption_generator.build_model(sess)\n",
    "\n",
    "        saver = tf.train.Saver(max_to_keep=50)\n",
    "        train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "        iteration_per_epoch = loaders['train'].getNumCaptions() / model_params['batch_size']\n",
    "        for epoch in range(n_epochs):\n",
    "            for bi in range(iteration_per_epoch):\n",
    "                # load batch data\n",
    "                batch = loaders['train'].getBatch(model_params['batch_size'])\n",
    "\n",
    "                #if bi % 50 == 0: \n",
    "                _, prob_value, loss_value = sess.run([train_op, prob, loss], \n",
    "                                         feed_dict={image: batch['images'],\n",
    "                                                    input_labels: batch['caption_labels'],\n",
    "                                                    target_labels: batch['target_labels'],\n",
    "                                                    mask: batch['caption_masks']}\n",
    "                                        )\n",
    "\n",
    "                if bi % 50 == 0:\n",
    "                    single_sample = []\n",
    "                    word_index = np.argmax(prob_value, 1)\n",
    "                    for wi in range(15):\n",
    "                        single_sample.append(word_index[wi])\n",
    "                    word_index = np.hstack(single_sample)\n",
    "\n",
    "                    generated_sentence = ''\n",
    "                    for w in word_index:\n",
    "                        word = itow[str(w)]\n",
    "                        if word == '<E>': break\n",
    "                        else:\n",
    "                            generated_sentence += (word + ' ')\n",
    "\n",
    "                    print('Sampled caption: ', generated_sentence)\n",
    "                    print \"%d epoch %d iteration Cost: %.4f\" % (epoch+1, bi, loss_value)\n",
    "\n",
    "            print \"Epoch \", epoch+1, \" is done. Saving the model ... \"\n",
    "            if not os.path.isdir(model_path):\n",
    "                os.makedirs(model_path)\n",
    "            saver.save(sess, os.path.join(model_path, 'model'), global_step=epoch+1)\n",
    "            learning_rate *= 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def embedding_images(sess, images, encoded_images):\n",
    "    embedded_images = sess.run(encoded_images, feed_dict={'image_raw:0': images})\n",
    "    return embedded_images\n",
    "\n",
    "def feed_image(sess, encoded_image):\n",
    "    initial_state = sess.run(fetches='lstm/initial_state:0',\n",
    "                            feed_dict={'image_feed:0': encoded_image})\n",
    "    return initial_state\n",
    "    \n",
    "\n",
    "def inference_step(sess, input_feed, state_feed):\n",
    "    softmax_output, state_output = sess.run(\n",
    "        fetches=[\"softmax:0\", \"lstm/state:0\"],\n",
    "        feed_dict={\n",
    "            \"input_feed:0\": input_feed,\n",
    "            \"lstm/state_feed:0\": state_feed,\n",
    "        })\n",
    "    return softmax_output, state_output, None\n",
    "\n",
    "\n",
    "def test(model_path='./models/model-0', maxlen=15):\n",
    "    tf.reset_default_graph()\n",
    "    with tf.Session() as sess:\n",
    "    \n",
    "        # create caption generator for test\n",
    "        model_params['batch_size'] = 1\n",
    "        caption_generator = Caption_Generator(model_params)\n",
    "        image, image_feat, image_embed, s_feed, prob = caption_generator.build_generator(sess=sess)\n",
    "\n",
    "        # load the model parameters\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, model_path)\n",
    "\n",
    "        itow = loaders['test'].getItow()\n",
    "        start_idx = loaders['test'].getWtoi()['<S>']\n",
    "        n_steps = loaders['train'].getMaxCaptionLength()\n",
    "        predictions = []\n",
    "        iteration_per_epoch = loaders['test'].getNumCaptions() / model_params['batch_size']\n",
    "        for bi in range(50):\n",
    "            # load batch data\n",
    "            batch = loaders['test'].getBatch(model_params['batch_size'])\n",
    "\n",
    "            # extract vgg feature\n",
    "            encoded_images = embedding_images(sess, batch['images'], image_feat)\n",
    "            input_feed = np.full((model_params['batch_size']), start_idx)\n",
    "            state_feed = feed_image(sess, encoded_images) # initial state\n",
    "            \n",
    "            generated_word_index = []\n",
    "            for ci in range(n_steps):\n",
    "                softmax, next_states, metadata = inference_step(sess, input_feed, state_feed)\n",
    "                \n",
    "                input_feed = np.argmax(softmax,1)\n",
    "                state_feed = next_states\n",
    "                \n",
    "                generated_word_index.append(input_feed[0])\n",
    "            \n",
    "            generated_sentence = ''\n",
    "            for w in generated_word_index:\n",
    "                word = itow[str(w)]\n",
    "                if word == '<E>': break\n",
    "                else:\n",
    "                    generated_sentence += (word + ' ')\n",
    "\n",
    "            img = np.asarray(batch['images'].reshape(224,224,3) \n",
    "                             + np.array([123.68, 116.779, 103.939]).reshape(1,1,3),dtype='uint8')\n",
    "            I=Image.fromarray(img)\n",
    "            plt.imshow(I)\n",
    "            plt.show()\n",
    "\n",
    "            print('Generated Caption: ', generated_sentence)\n",
    "\n",
    "            ith_prediction = {}\n",
    "            ith_prediction['image_id'] = batch['image_ids'][0]\n",
    "            ith_prediction['caption'] = generated_sentence\n",
    "            predictions.append(ith_prediction)\n",
    "            \n",
    "\n",
    "        # save the prediction outputs\n",
    "        if not os.path.isdir('result'):\n",
    "                os.makedirs('result')\n",
    "        write_json('result/predictions.json', predictions)\n",
    "        print('Save the predictions to result/predictions.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Training and Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value word_embedding/word_embedding_matrix/Adam\n\t [[Node: word_embedding/word_embedding_matrix/Adam/read = Identity[T=DT_FLOAT, _class=[\"loc:@word_embedding/word_embedding_matrix\"], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](word_embedding/word_embedding_matrix/Adam)]]\n\nCaused by op u'word_embedding/word_embedding_matrix/Adam/read', defined at:\n  File \"/home/daniel/anaconda2/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/home/daniel/anaconda2/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-ac6b01e813ce>\", line 4, in <module>\n    train()\n  File \"<ipython-input-4-02c7a6de262e>\", line 41, in train\n    train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 325, in minimize\n    name=name)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 446, in apply_gradients\n    self._create_slots([_get_variable_for(v) for v in var_list])\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/adam.py\", line 122, in _create_slots\n    self._zeros_slot(v, \"m\", self._name)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 766, in _zeros_slot\n    named_slots[_var_key(var)] = slot_creator.create_zeros_slot(var, op_name)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/slot_creator.py\", line 174, in create_zeros_slot\n    colocate_with_primary=colocate_with_primary)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/slot_creator.py\", line 146, in create_slot_with_initializer\n    dtype)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/slot_creator.py\", line 66, in _create_slot_var\n    validate_shape=validate_shape)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 1049, in get_variable\n    use_resource=use_resource, custom_getter=custom_getter)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 948, in get_variable\n    use_resource=use_resource, custom_getter=custom_getter)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 356, in get_variable\n    validate_shape=validate_shape, use_resource=use_resource)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 341, in _true_getter\n    use_resource=use_resource)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 714, in _get_single_variable\n    validate_shape=validate_shape)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 197, in __init__\n    expected_shape=expected_shape)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 316, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1338, in identity\n    result = _op_def_lib.apply_op(\"Identity\", input=input, name=name)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value word_embedding/word_embedding_matrix/Adam\n\t [[Node: word_embedding/word_embedding_matrix/Adam/read = Identity[T=DT_FLOAT, _class=[\"loc:@word_embedding/word_embedding_matrix\"], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](word_embedding/word_embedding_matrix/Adam)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ac6b01e813ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdo_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdo_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-02c7a6de262e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m                                                     \u001b[0minput_labels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'caption_labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                                                     \u001b[0mtarget_labels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target_labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                                                     mask: batch['caption_masks']}\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         )\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/daniel/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/daniel/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/daniel/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/daniel/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value word_embedding/word_embedding_matrix/Adam\n\t [[Node: word_embedding/word_embedding_matrix/Adam/read = Identity[T=DT_FLOAT, _class=[\"loc:@word_embedding/word_embedding_matrix\"], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](word_embedding/word_embedding_matrix/Adam)]]\n\nCaused by op u'word_embedding/word_embedding_matrix/Adam/read', defined at:\n  File \"/home/daniel/anaconda2/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/home/daniel/anaconda2/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-ac6b01e813ce>\", line 4, in <module>\n    train()\n  File \"<ipython-input-4-02c7a6de262e>\", line 41, in train\n    train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 325, in minimize\n    name=name)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 446, in apply_gradients\n    self._create_slots([_get_variable_for(v) for v in var_list])\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/adam.py\", line 122, in _create_slots\n    self._zeros_slot(v, \"m\", self._name)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 766, in _zeros_slot\n    named_slots[_var_key(var)] = slot_creator.create_zeros_slot(var, op_name)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/slot_creator.py\", line 174, in create_zeros_slot\n    colocate_with_primary=colocate_with_primary)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/slot_creator.py\", line 146, in create_slot_with_initializer\n    dtype)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/slot_creator.py\", line 66, in _create_slot_var\n    validate_shape=validate_shape)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 1049, in get_variable\n    use_resource=use_resource, custom_getter=custom_getter)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 948, in get_variable\n    use_resource=use_resource, custom_getter=custom_getter)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 356, in get_variable\n    validate_shape=validate_shape, use_resource=use_resource)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 341, in _true_getter\n    use_resource=use_resource)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 714, in _get_single_variable\n    validate_shape=validate_shape)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 197, in __init__\n    expected_shape=expected_shape)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 316, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1338, in identity\n    result = _op_def_lib.apply_op(\"Identity\", input=input, name=name)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/daniel/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value word_embedding/word_embedding_matrix/Adam\n\t [[Node: word_embedding/word_embedding_matrix/Adam/read = Identity[T=DT_FLOAT, _class=[\"loc:@word_embedding/word_embedding_matrix\"], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](word_embedding/word_embedding_matrix/Adam)]]\n"
     ]
    }
   ],
   "source": [
    "# test model that means to predict captions for test images\n",
    "do_train = True\n",
    "if do_train:\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test model that means to predict captions for test images\n",
    "if not do_train:\n",
    "    test(model_path='models/model-7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.tools.inspect_checkpoint import print_tensors_in_checkpoint_file\n",
    "\n",
    "print_tensors_in_checkpoint_file('models/model.ckpt-1', tensor_name='lstm/basic_lstm_cell/weights', all_tensors=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append('coco-caption')\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "from pycocoevalcap.eval import COCOEvalCap\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io as io\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "\n",
    "import json\n",
    "from json import encoder\n",
    "encoder.FLOAT_REPR = lambda o: format(o, '.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ann_file = 'coco-caption/annotations/captions_val2014.json'\n",
    "res_file = 'result/predictions.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create coco object and cocoRes object\n",
    "coco = COCO(ann_file)\n",
    "cocoRes = coco.loadRes(res_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create cocoEval object by taking coco and cocoRes\n",
    "cocoEval = COCOEvalCap(coco, cocoRes)\n",
    "\n",
    "# evaluate on a subset of images by setting\n",
    "# cocoEval.params['image_id'] = cocoRes.getImgIds()\n",
    "# please remove this line when evaluating the full validation set\n",
    "cocoEval.params['image_id'] = cocoRes.getImgIds()\n",
    "\n",
    "# evaluate results\n",
    "cocoEval.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
